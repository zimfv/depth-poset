{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae136d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/scistore16/edelgrp/fzimin/depth-poset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156d4346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2904808/126727491.py\", line 4, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/nfs/scistore16/edelgrp/fzimin/.local/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/mnt/nfs/clustersw/Debian/bookworm/jupyterhub/1.0/lib/python3.11/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import gudhi as gh\n",
    "import pickle as pkl\n",
    "\n",
    "from src.depth import DepthPoset\n",
    "\n",
    "\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from networkx import draw_networkx\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib import lines as mlines\n",
    "\n",
    "from src.depth import DepthPoset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2f7232",
   "metadata": {},
   "source": [
    "# Load and Format the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ed936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 621/687 [01:25<00:18,  3.52it/s] "
     ]
    }
   ],
   "source": [
    "directory = \"results/transpositions-during-linear-homotopy-between-barycentric-cubical-toruses\"\n",
    "paths = np.sort([f'{directory}/{f}' for f in os.listdir(directory)])\n",
    "\n",
    "# the files are too big\n",
    "#paths = paths[:420]\n",
    "\n",
    "#df = pd.concat([pd.read_pickle(path) for path in tqdm(paths)])\n",
    "df = []\n",
    "errs = {}\n",
    "for path in tqdm(paths):\n",
    "    if os.path.getsize(path) < np.inf*1024**2:\n",
    "        try:\n",
    "            with open(path, 'rb') as file:\n",
    "                loaded_dict = pkl.load(file)\n",
    "            loaded_dict['transpositions'].insert(0, 'complex_index0', loaded_dict['complex_index0'])\n",
    "            loaded_dict['transpositions'].insert(1, 'complex_index1', loaded_dict['complex_index1'])\n",
    "            loaded_dict['transpositions'].insert(2, 'complex_dim', loaded_dict['complex_dim'])\n",
    "            loaded_dict['transpositions'].insert(3, 'complex_shape', [loaded_dict['complex_shape']]*len(loaded_dict['transpositions']))\n",
    "            df.append(loaded_dict['transpositions'])\n",
    "\n",
    "        except Exception as err:\n",
    "            errs.update({path: err})\n",
    "    else:\n",
    "        errs.update({path: 'Giant file'})\n",
    "errs = pd.Series(errs)\n",
    "if len(errs) > 0:\n",
    "    errs_count = errs.astype(str).value_counts()\n",
    "    print(f'There is some amount of errors:\\n{errs_count.to_string(name=False)}\\n')\n",
    "    #for path in errs.index:\n",
    "    #    if os.path.exists(path):\n",
    "    #        os.remove(path)\n",
    "    \n",
    "df = pd.concat(df)\n",
    "\n",
    "if not 'complex_n' in df.columns: \n",
    "    df.insert(3, 'complex_n', df['complex_shape'].apply(lambda x: x[0] if (np.array(x)[1:] == np.array(x)[:-1]).all() else None))\n",
    "\n",
    "#print(f'There are {pd.isna(df['transposition']).sum()} empty transposition values in {len(df)} lines')\n",
    "#df = df[~pd.isna(df['transposition'])]\n",
    "df = df.join(df['transposition'].apply(lambda tr: tr.to_dict()).apply(pd.Series))\n",
    "\n",
    "print(f'df.shape = {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147656ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict['transpositions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f26b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e94b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['complex_index0', 'complex_index1', 'complex_dim', 'complex_n']\n",
    "           )['index 0'].count().reset_index().groupby(['complex_dim', 'complex_n']\n",
    "            )['complex_index0'].count().reset_index().pivot_table(columns='complex_dim', index='complex_n', values='complex_index0').fillna(0).astype(int).plot(kind='barh', width=0.8)\n",
    "\n",
    "plt.xlabel('Number of Pairs')\n",
    "xticks, _ = plt.xticks()\n",
    "xticks = np.unique(np.array(xticks).astype(int))\n",
    "plt.xticks(xticks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e385e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_switch_types = df.copy()\n",
    "\n",
    "df_switch_types.loc[(df_switch_types['switch'] == 'switch forward') | (df_switch_types['switch'] == 'switch backward'), 'switch'] = 'switch'\n",
    "df_switch_types['switch type'] = df_switch_types.apply(lambda row: row['type'] if row['switch'] == 'switch' else row['switch'], axis=1)\n",
    "\n",
    "df_switch_types = df_switch_types.groupby(['complex_index0', 'complex_index1', 'complex_dim', 'complex_n', 'dim', 'switch type'])['index 0'].count().reset_index().rename(columns={'index 0': 'count'})\n",
    "df_switch_types = df_switch_types.groupby(['complex_dim', 'complex_n', 'dim', 'switch type'])['count'].mean().reset_index()\n",
    "df_switch_types = df_switch_types.pivot_table(index='complex_n', columns=['complex_dim', 'dim', 'switch type'], values='count')\n",
    "\n",
    "complex_dims = pd.unique(df['complex_dim'])\n",
    "transposition_dims = pd.unique(df['dim'])\n",
    "\n",
    "fig, axs = plt.subplots(len(complex_dims), len(transposition_dims), figsize=(4*len(transposition_dims), 3*len(complex_dims) + 1), squeeze=False)\n",
    "fig.suptitle('The distribution of Transposition Types by the Size of the Torus $n$')\n",
    "for i, complex_dim in enumerate(complex_dims):\n",
    "    for j, transposition_dim in enumerate(transposition_dims):\n",
    "        try:\n",
    "            df_switch_types[complex_dim][transposition_dim].plot(ax=axs[i, j], marker='.')\n",
    "            axs[i, j].set_title(f'{transposition_dim}-dim transpositions in $\\\\mathbb{{T}}^{{\\;{complex_dim}}}$')\n",
    "            axs[i, j].grid(True)\n",
    "            axs[i, j].set_xlabel('n')\n",
    "        except KeyError:\n",
    "            axs[i, j].set_xticks([])\n",
    "            axs[i, j].set_yticks([])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76452723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
